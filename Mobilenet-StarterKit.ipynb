{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL3\n",
    "Follow this notebook only if you're new to DeepLearing and Transfer learning. This is a extension of the Startet kit given [here](https://github.com/shubham3121/DL-3/blob/master/DL%233_EDA.ipynb). I'll try to keep it simple. Please ignore the typos :)\n",
    "\n",
    "### Why to use Mobilenet architecture?\n",
    "You might have seen multiple tutorials on the VGG16 based transfer learning but here I'm going to use Mobilenet because of the following reasons \n",
    "<ul>\n",
    "    <li> No. of parameters to train in Mobilenet is quite less in compare to the VGG16\n",
    "    <li> Having fewer parameters will make your training time less and you'll be able to do more experiment and your chances of wining becames higher.\n",
    "    <li> On top of above reasons Mobile net has similar performance on the ImageNet dataset as VGG16\n",
    "</ul>\n",
    "\n",
    "Having said that let move on to the imorting important libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications import MobileNet\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use 128x128 images. You can change that if you wish.\n",
    "\n",
    "My folder structure is as follow\n",
    "\n",
    "<ul>\n",
    "    <li> DL3</li>\n",
    "        <ul>\n",
    "            <li> starter_kit</li>\n",
    "                <ul>\n",
    "                    <li> this_notebook</li>\n",
    "                </ul>\n",
    "            <li> data</li>\n",
    "                <ul>\n",
    "                    <li> train_img</li>\n",
    "                    <li> test_img</li>\n",
    "                </ul>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = (128, 128)\n",
    "\n",
    "train_data_dir = '/home/suraj/Repositories/Datasets/DL3 Dataset/train_img/'\n",
    "test_data_dir = '/home/suraj/Repositories/Datasets/DL3 Dataset/test_img/'\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mobile_model = MobileNet(include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "# add a global spatial average pooling layer\n",
    "    x = Mobile_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(85, activation='sigmoid')(x)\n",
    "    model = Model(inputs=Mobile_model.input, outputs=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with training the head(last layer) only as that layer is initialized randomaly and we don't want to affect the other layers weights as while backpropogation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 85)                87125     \n",
      "=================================================================\n",
      "Total params: 3,315,989\n",
      "Trainable params: 87,125\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#train only last layer\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2,\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, rotation_range = 20)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/suraj/Repositories/Datasets/DL3 Dataset/meta-data/train.csv', index_col=0)\n",
    "test = pd.read_csv('/home/suraj/Repositories/Datasets/DL3 Dataset/meta-data/test.csv')\n",
    "attributes = pd.read_csv('/home/suraj/Repositories/Datasets/DL3 Dataset/attributes.txt', delimiter='\\t', header=None, index_col=0)\n",
    "classes = pd.read_csv('/home/suraj/Repositories/Datasets/DL3 Dataset/classes.txt', delimiter='\\t', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(src, df, labels = False):\n",
    "    if labels == False:\n",
    "        imgs = []    \n",
    "        files = df['Image_name'].values\n",
    "        for file in tqdm(files):\n",
    "            im = cv.imread(os.path.join(src, file))\n",
    "            im = cv.resize(im, (img_width, img_height))\n",
    "            imgs.append(im)\n",
    "        return np.array(imgs)\n",
    "    else:\n",
    "        imgs = []\n",
    "        labels = []\n",
    "        files = os.listdir(src)\n",
    "        for file in tqdm(files):\n",
    "            im = cv.imread(os.path.join(src, file))\n",
    "            im = cv.resize(im, (img_width, img_height))\n",
    "            imgs.append(im)\n",
    "            labels.append(df.loc[file].values)\n",
    "        return np.array(imgs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 330/12600 [00:09<06:07, 33.42it/s]/home/suraj/.local/lib/python2.7/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 12600/12600 [05:10<00:00, 40.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs, train_labels = get_imgs(train_data_dir, train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2856"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train val split\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(train_imgs, train_labels, test_size = 3000, random_state = 222)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(X_tra)\n",
    "val_datagen.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmeasure(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to train our model with SGD and very low learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1e2c13983ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmeasure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "early_stp = EarlyStopping(patience=3)\n",
    "model_ckpt = ModelCheckpoint('mobilenet_1_layer.h5', save_weights_only=True)\n",
    "\n",
    "opt = optimizers.SGD(lr=0.001, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(opt, loss = 'binary_crossentropy', metrics=['accuracy', fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "75/75 [==============================] - 28s 372ms/step - loss: 0.7833 - acc: 0.5606 - fmeasure: 0.4405 - val_loss: 0.6931 - val_acc: 0.6205 - val_fmeasure: 0.4994\n",
      "Epoch 2/25\n",
      "75/75 [==============================] - 22s 288ms/step - loss: 0.6383 - acc: 0.6639 - fmeasure: 0.5381 - val_loss: 0.6262 - val_acc: 0.6751 - val_fmeasure: 0.5556\n",
      "Epoch 3/25\n",
      "75/75 [==============================] - 21s 283ms/step - loss: 0.5983 - acc: 0.6987 - fmeasure: 0.5752 - val_loss: 0.6016 - val_acc: 0.6956 - val_fmeasure: 0.5778\n",
      "Epoch 4/25\n",
      "75/75 [==============================] - 21s 275ms/step - loss: 0.5819 - acc: 0.7128 - fmeasure: 0.5910 - val_loss: 0.5889 - val_acc: 0.7055 - val_fmeasure: 0.5888\n",
      "Epoch 5/25\n",
      "75/75 [==============================] - 20s 269ms/step - loss: 0.5738 - acc: 0.7196 - fmeasure: 0.5991 - val_loss: 0.5805 - val_acc: 0.7114 - val_fmeasure: 0.5959\n",
      "Epoch 6/25\n",
      "75/75 [==============================] - 20s 273ms/step - loss: 0.5665 - acc: 0.7248 - fmeasure: 0.6059 - val_loss: 0.5740 - val_acc: 0.7156 - val_fmeasure: 0.6011\n",
      "Epoch 7/25\n",
      "75/75 [==============================] - 20s 265ms/step - loss: 0.5608 - acc: 0.7281 - fmeasure: 0.6101 - val_loss: 0.5686 - val_acc: 0.7186 - val_fmeasure: 0.6047\n",
      "Epoch 8/25\n",
      "75/75 [==============================] - 21s 275ms/step - loss: 0.5564 - acc: 0.7309 - fmeasure: 0.6137 - val_loss: 0.5638 - val_acc: 0.7214 - val_fmeasure: 0.6081\n",
      "Epoch 9/25\n",
      "75/75 [==============================] - 20s 263ms/step - loss: 0.5525 - acc: 0.7329 - fmeasure: 0.6167 - val_loss: 0.5593 - val_acc: 0.7235 - val_fmeasure: 0.6110\n",
      "Epoch 10/25\n",
      "75/75 [==============================] - 20s 262ms/step - loss: 0.5475 - acc: 0.7353 - fmeasure: 0.6199 - val_loss: 0.5553 - val_acc: 0.7258 - val_fmeasure: 0.6138\n",
      "Epoch 11/25\n",
      "75/75 [==============================] - 20s 263ms/step - loss: 0.5432 - acc: 0.7378 - fmeasure: 0.6234 - val_loss: 0.5513 - val_acc: 0.7279 - val_fmeasure: 0.6167\n",
      "Epoch 12/25\n",
      "75/75 [==============================] - 20s 271ms/step - loss: 0.5398 - acc: 0.7395 - fmeasure: 0.6257 - val_loss: 0.5476 - val_acc: 0.7297 - val_fmeasure: 0.6192\n",
      "Epoch 13/25\n",
      "75/75 [==============================] - 21s 276ms/step - loss: 0.5361 - acc: 0.7413 - fmeasure: 0.6282 - val_loss: 0.5440 - val_acc: 0.7317 - val_fmeasure: 0.6219\n",
      "Epoch 14/25\n",
      "75/75 [==============================] - 20s 273ms/step - loss: 0.5326 - acc: 0.7430 - fmeasure: 0.6307 - val_loss: 0.5406 - val_acc: 0.7336 - val_fmeasure: 0.6244\n",
      "Epoch 15/25\n",
      "75/75 [==============================] - 21s 279ms/step - loss: 0.5294 - acc: 0.7449 - fmeasure: 0.6336 - val_loss: 0.5373 - val_acc: 0.7355 - val_fmeasure: 0.6270\n",
      "Epoch 16/25\n",
      "75/75 [==============================] - 21s 280ms/step - loss: 0.5256 - acc: 0.7471 - fmeasure: 0.6365 - val_loss: 0.5342 - val_acc: 0.7371 - val_fmeasure: 0.6294\n",
      "Epoch 17/25\n",
      "75/75 [==============================] - 21s 281ms/step - loss: 0.5218 - acc: 0.7488 - fmeasure: 0.6392 - val_loss: 0.5311 - val_acc: 0.7387 - val_fmeasure: 0.6315\n",
      "Epoch 18/25\n",
      "75/75 [==============================] - 21s 279ms/step - loss: 0.5200 - acc: 0.7500 - fmeasure: 0.6409 - val_loss: 0.5281 - val_acc: 0.7403 - val_fmeasure: 0.6337\n",
      "Epoch 19/25\n",
      "75/75 [==============================] - 21s 282ms/step - loss: 0.5163 - acc: 0.7516 - fmeasure: 0.6432 - val_loss: 0.5252 - val_acc: 0.7419 - val_fmeasure: 0.6359\n",
      "Epoch 20/25\n",
      "75/75 [==============================] - 21s 286ms/step - loss: 0.5135 - acc: 0.7538 - fmeasure: 0.6463 - val_loss: 0.5225 - val_acc: 0.7436 - val_fmeasure: 0.6382\n",
      "Epoch 21/25\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 0.5112 - acc: 0.7546 - fmeasure: 0.6475 - val_loss: 0.5197 - val_acc: 0.7451 - val_fmeasure: 0.6403\n",
      "Epoch 22/25\n",
      "75/75 [==============================] - 21s 280ms/step - loss: 0.5075 - acc: 0.7567 - fmeasure: 0.6507 - val_loss: 0.5171 - val_acc: 0.7465 - val_fmeasure: 0.6423\n",
      "Epoch 23/25\n",
      "75/75 [==============================] - 21s 277ms/step - loss: 0.5047 - acc: 0.7579 - fmeasure: 0.6526 - val_loss: 0.5145 - val_acc: 0.7482 - val_fmeasure: 0.6446\n",
      "Epoch 24/25\n",
      "75/75 [==============================] - 20s 270ms/step - loss: 0.5027 - acc: 0.7593 - fmeasure: 0.6543 - val_loss: 0.5120 - val_acc: 0.7495 - val_fmeasure: 0.6463\n",
      "Epoch 25/25\n",
      "75/75 [==============================] - 20s 268ms/step - loss: 0.5006 - acc: 0.7600 - fmeasure: 0.6557 - val_loss: 0.5095 - val_acc: 0.7509 - val_fmeasure: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a0bbc96d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_datagen.flow(X_tra, y_tra, batch_size=batch_size),                     \n",
    "                    steps_per_epoch=len(X_tra) / batch_size, epochs=25,\n",
    "                    validation_data=val_datagen.flow(X_val, y_val, batch_size=batch_size), \n",
    "                    validation_steps = len(X_val)/batch_size, callbacks=[early_stp, model_ckpt], workers = 10, max_queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 85)                87125     \n",
      "=================================================================\n",
      "Total params: 3,315,989\n",
      "Trainable params: 3,294,101\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "#train only last 10 layer\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "opt = optimizers.SGD(lr=0.001, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(opt, loss = 'binary_crossentropy', metrics=['accuracy', fmeasure])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stp = EarlyStopping(patience=3)\n",
    "model_ckpt = ModelCheckpoint('mobilenet_all_layers.h5', save_weights_only=True)\n",
    "model.load_weights('mobilenet_1_layer.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "384/384 [==============================] - 64s 167ms/step - loss: 0.2953 - acc: 0.8719 - fmeasure: 0.8207 - val_loss: 0.2822 - val_acc: 0.8785 - val_fmeasure: 0.8292\n",
      "Epoch 2/75\n",
      "384/384 [==============================] - 63s 163ms/step - loss: 0.2907 - acc: 0.8742 - fmeasure: 0.8240 - val_loss: 0.2761 - val_acc: 0.8809 - val_fmeasure: 0.8328\n",
      "Epoch 3/75\n",
      "384/384 [==============================] - 63s 164ms/step - loss: 0.2852 - acc: 0.8766 - fmeasure: 0.8275 - val_loss: 0.2714 - val_acc: 0.8836 - val_fmeasure: 0.8367\n",
      "Epoch 4/75\n",
      "384/384 [==============================] - 62s 161ms/step - loss: 0.2811 - acc: 0.8788 - fmeasure: 0.8309 - val_loss: 0.2672 - val_acc: 0.8855 - val_fmeasure: 0.8392\n",
      "Epoch 5/75\n",
      "384/384 [==============================] - 63s 165ms/step - loss: 0.2789 - acc: 0.8798 - fmeasure: 0.8321 - val_loss: 0.2645 - val_acc: 0.8868 - val_fmeasure: 0.8411\n",
      "Epoch 6/75\n",
      "384/384 [==============================] - 62s 162ms/step - loss: 0.2732 - acc: 0.8833 - fmeasure: 0.8370 - val_loss: 0.2591 - val_acc: 0.8897 - val_fmeasure: 0.8454\n",
      "Epoch 7/75\n",
      "384/384 [==============================] - 63s 163ms/step - loss: 0.2694 - acc: 0.8848 - fmeasure: 0.8393 - val_loss: 0.2569 - val_acc: 0.8905 - val_fmeasure: 0.8466\n",
      "Epoch 8/75\n",
      "384/384 [==============================] - 62s 161ms/step - loss: 0.2667 - acc: 0.8862 - fmeasure: 0.8412 - val_loss: 0.2520 - val_acc: 0.8927 - val_fmeasure: 0.8499\n",
      "Epoch 9/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2615 - acc: 0.8889 - fmeasure: 0.8452 - val_loss: 0.2494 - val_acc: 0.8942 - val_fmeasure: 0.8518\n",
      "Epoch 10/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2593 - acc: 0.8899 - fmeasure: 0.8466 - val_loss: 0.2469 - val_acc: 0.8955 - val_fmeasure: 0.8538\n",
      "Epoch 11/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2566 - acc: 0.8912 - fmeasure: 0.8485 - val_loss: 0.2444 - val_acc: 0.8963 - val_fmeasure: 0.8549\n",
      "Epoch 12/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2536 - acc: 0.8926 - fmeasure: 0.8505 - val_loss: 0.2397 - val_acc: 0.8986 - val_fmeasure: 0.8583\n",
      "Epoch 13/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2518 - acc: 0.8931 - fmeasure: 0.8511 - val_loss: 0.2379 - val_acc: 0.8996 - val_fmeasure: 0.8596\n",
      "Epoch 14/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2474 - acc: 0.8955 - fmeasure: 0.8547 - val_loss: 0.2336 - val_acc: 0.9018 - val_fmeasure: 0.8629\n",
      "Epoch 15/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2452 - acc: 0.8964 - fmeasure: 0.8556 - val_loss: 0.2325 - val_acc: 0.9022 - val_fmeasure: 0.8634\n",
      "Epoch 16/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2416 - acc: 0.8985 - fmeasure: 0.8588 - val_loss: 0.2286 - val_acc: 0.9039 - val_fmeasure: 0.8658\n",
      "Epoch 17/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2395 - acc: 0.8991 - fmeasure: 0.8596 - val_loss: 0.2279 - val_acc: 0.9040 - val_fmeasure: 0.8661\n",
      "Epoch 18/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2381 - acc: 0.9002 - fmeasure: 0.8613 - val_loss: 0.2250 - val_acc: 0.9055 - val_fmeasure: 0.8682\n",
      "Epoch 19/75\n",
      "384/384 [==============================] - 60s 156ms/step - loss: 0.2343 - acc: 0.9022 - fmeasure: 0.8641 - val_loss: 0.2243 - val_acc: 0.9058 - val_fmeasure: 0.8686\n",
      "Epoch 20/75\n",
      "384/384 [==============================] - 63s 164ms/step - loss: 0.2318 - acc: 0.9030 - fmeasure: 0.8652 - val_loss: 0.2231 - val_acc: 0.9063 - val_fmeasure: 0.8692\n",
      "Epoch 21/75\n",
      "384/384 [==============================] - 64s 166ms/step - loss: 0.2307 - acc: 0.9036 - fmeasure: 0.8660 - val_loss: 0.2210 - val_acc: 0.9072 - val_fmeasure: 0.8707\n",
      "Epoch 22/75\n",
      "384/384 [==============================] - 62s 163ms/step - loss: 0.2274 - acc: 0.9054 - fmeasure: 0.8685 - val_loss: 0.2196 - val_acc: 0.9080 - val_fmeasure: 0.8719\n",
      "Epoch 23/75\n",
      "384/384 [==============================] - 65s 169ms/step - loss: 0.2247 - acc: 0.9061 - fmeasure: 0.8696 - val_loss: 0.2173 - val_acc: 0.9090 - val_fmeasure: 0.8732\n",
      "Epoch 24/75\n",
      "  6/384 [..............................] - ETA: 10:30 - loss: 0.2163 - acc: 0.9101 - fmeasure: 0.8764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/.local/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.176332). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 72s 188ms/step - loss: 0.2239 - acc: 0.9068 - fmeasure: 0.8705 - val_loss: 0.2144 - val_acc: 0.9104 - val_fmeasure: 0.8753\n",
      "Epoch 25/75\n",
      "384/384 [==============================] - 64s 167ms/step - loss: 0.2207 - acc: 0.9086 - fmeasure: 0.8731 - val_loss: 0.2144 - val_acc: 0.9102 - val_fmeasure: 0.8749\n",
      "Epoch 26/75\n",
      "384/384 [==============================] - 63s 165ms/step - loss: 0.2193 - acc: 0.9091 - fmeasure: 0.8738 - val_loss: 0.2120 - val_acc: 0.9112 - val_fmeasure: 0.8763\n",
      "Epoch 27/75\n",
      "384/384 [==============================] - 62s 161ms/step - loss: 0.2173 - acc: 0.9099 - fmeasure: 0.8751 - val_loss: 0.2102 - val_acc: 0.9122 - val_fmeasure: 0.8779\n",
      "Epoch 28/75\n",
      "384/384 [==============================] - 61s 160ms/step - loss: 0.2167 - acc: 0.9099 - fmeasure: 0.8749 - val_loss: 0.2097 - val_acc: 0.9121 - val_fmeasure: 0.8776\n",
      "Epoch 29/75\n",
      "384/384 [==============================] - 61s 159ms/step - loss: 0.2150 - acc: 0.9109 - fmeasure: 0.8763 - val_loss: 0.2076 - val_acc: 0.9131 - val_fmeasure: 0.8792\n",
      "Epoch 30/75\n",
      "384/384 [==============================] - 63s 164ms/step - loss: 0.2101 - acc: 0.9131 - fmeasure: 0.8796 - val_loss: 0.2045 - val_acc: 0.9146 - val_fmeasure: 0.8812\n",
      "Epoch 31/75\n",
      "384/384 [==============================] - 62s 161ms/step - loss: 0.2088 - acc: 0.9135 - fmeasure: 0.8800 - val_loss: 0.2037 - val_acc: 0.9150 - val_fmeasure: 0.8817\n",
      "Epoch 32/75\n",
      "384/384 [==============================] - 61s 159ms/step - loss: 0.2099 - acc: 0.9130 - fmeasure: 0.8793 - val_loss: 0.2021 - val_acc: 0.9157 - val_fmeasure: 0.8827\n",
      "Epoch 33/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.2055 - acc: 0.9156 - fmeasure: 0.8830 - val_loss: 0.2016 - val_acc: 0.9159 - val_fmeasure: 0.8831\n",
      "Epoch 34/75\n",
      "384/384 [==============================] - 61s 159ms/step - loss: 0.2044 - acc: 0.9153 - fmeasure: 0.8825 - val_loss: 0.1991 - val_acc: 0.9168 - val_fmeasure: 0.8845\n",
      "Epoch 35/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.2041 - acc: 0.9159 - fmeasure: 0.8834 - val_loss: 0.1997 - val_acc: 0.9166 - val_fmeasure: 0.8841\n",
      "Epoch 36/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.2003 - acc: 0.9177 - fmeasure: 0.8859 - val_loss: 0.1969 - val_acc: 0.9179 - val_fmeasure: 0.8858\n",
      "Epoch 37/75\n",
      "384/384 [==============================] - 60s 158ms/step - loss: 0.1992 - acc: 0.9179 - fmeasure: 0.8862 - val_loss: 0.1972 - val_acc: 0.9179 - val_fmeasure: 0.8858\n",
      "Epoch 38/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.1986 - acc: 0.9180 - fmeasure: 0.8864 - val_loss: 0.1957 - val_acc: 0.9187 - val_fmeasure: 0.8869\n",
      "Epoch 39/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.1969 - acc: 0.9193 - fmeasure: 0.8882 - val_loss: 0.1954 - val_acc: 0.9187 - val_fmeasure: 0.8870\n",
      "Epoch 40/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.1957 - acc: 0.9198 - fmeasure: 0.8889 - val_loss: 0.1960 - val_acc: 0.9182 - val_fmeasure: 0.8862\n",
      "Epoch 41/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.1929 - acc: 0.9208 - fmeasure: 0.8904 - val_loss: 0.1929 - val_acc: 0.9195 - val_fmeasure: 0.8881\n",
      "Epoch 42/75\n",
      "384/384 [==============================] - 60s 157ms/step - loss: 0.1903 - acc: 0.9221 - fmeasure: 0.8920 - val_loss: 0.1908 - val_acc: 0.9207 - val_fmeasure: 0.8898\n",
      "Epoch 43/75\n",
      "384/384 [==============================] - 61s 158ms/step - loss: 0.1913 - acc: 0.9218 - fmeasure: 0.8917 - val_loss: 0.1892 - val_acc: 0.9214 - val_fmeasure: 0.8907\n",
      "Epoch 44/75\n",
      " 97/384 [======>.......................] - ETA: 40s - loss: 0.1883 - acc: 0.9241 - fmeasure: 0.8952"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_datagen.flow(X_tra, y_tra, batch_size=25),                     \n",
    "                    steps_per_epoch=len(X_tra) / 25, epochs=75,\n",
    "                    validation_data=val_datagen.flow(X_val, y_val, batch_size=25), \n",
    "                    validation_steps = len(X_val)/25, callbacks=[early_stp, model_ckpt], workers = 10, max_queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5400/5400 [01:02<00:00, 86.87it/s]\n"
     ]
    }
   ],
   "source": [
    "test_imgs = get_imgs(test_data_dir, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen.fit(test_imgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 16s 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(test_datagen.flow(test_imgs, batch_size=512, shuffle=False), verbose=1, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>attrib_01</th>\n",
       "      <th>attrib_02</th>\n",
       "      <th>attrib_03</th>\n",
       "      <th>attrib_04</th>\n",
       "      <th>attrib_05</th>\n",
       "      <th>attrib_06</th>\n",
       "      <th>attrib_07</th>\n",
       "      <th>attrib_08</th>\n",
       "      <th>attrib_09</th>\n",
       "      <th>...</th>\n",
       "      <th>attrib_76</th>\n",
       "      <th>attrib_77</th>\n",
       "      <th>attrib_78</th>\n",
       "      <th>attrib_79</th>\n",
       "      <th>attrib_80</th>\n",
       "      <th>attrib_81</th>\n",
       "      <th>attrib_82</th>\n",
       "      <th>attrib_83</th>\n",
       "      <th>attrib_84</th>\n",
       "      <th>attrib_85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image-1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image-2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image-3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image-4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image-5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_name  attrib_01  attrib_02  attrib_03  attrib_04  attrib_05  \\\n",
       "0  Image-1.jpg          0          0          0          1          0   \n",
       "1  Image-2.jpg          0          1          0          1          0   \n",
       "2  Image-3.jpg          0          0          0          1          0   \n",
       "3  Image-4.jpg          1          0          0          0          0   \n",
       "4  Image-5.jpg          0          0          0          1          0   \n",
       "\n",
       "   attrib_06  attrib_07  attrib_08  attrib_09    ...      attrib_76  \\\n",
       "0          1          0          0          1    ...              0   \n",
       "1          1          1          0          0    ...              0   \n",
       "2          0          1          0          0    ...              0   \n",
       "3          1          0          0          1    ...              0   \n",
       "4          0          0          0          0    ...              0   \n",
       "\n",
       "   attrib_77  attrib_78  attrib_79  attrib_80  attrib_81  attrib_82  \\\n",
       "0          0          1          1          1          0          0   \n",
       "1          1          0          1          0          0          0   \n",
       "2          0          0          1          0          0          0   \n",
       "3          1          1          1          0          1          0   \n",
       "4          0          0          1          0          0          0   \n",
       "\n",
       "   attrib_83  attrib_84  attrib_85  \n",
       "0          1          0          0  \n",
       "1          0          1          1  \n",
       "2          0          0          1  \n",
       "3          1          0          1  \n",
       "4          1          0          0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/home/suraj/Repositories/Datasets/DL3 Dataset/meta-data/sample_submission.csv')\n",
    "sub.iloc[:, 1:] = pred.round().astype(int)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 86)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "This submission should get you around $\\approx$0.80 on the LB. and if you've noticed that our last epochs val_fmeasure is the same so it means that our val set is represantion of the test set and you can train for many epochs with EarlyStopping without worring about overfitting on val or train set.\n",
    "\n",
    "### How to improve from here?\n",
    "You can change many things which will let you get higher LB score. Following is a small list\n",
    "<ul>\n",
    "    <li> Change the Image size to bigger number </li>\n",
    "    <li> Increse the number of epoch in the fully trainable network($2^{nd}$ training) </li>\n",
    "    <li> Use diffrent architechure. you'll get more info on that [here](keras.io/applications/)</li>\n",
    "    <li> If nothing works ensemble is your best friend </li>\n",
    "</ul>\n",
    "\n",
    "I'll try to keep improving this notebook. Feel free to contribuite.\n",
    "\n",
    "Thanks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
